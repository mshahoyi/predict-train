"""
Surprise Mining method for preference prediction.

Intuition: training completions that most surprise the (un-finetuned) base model
may encode the teacher's implicit preference.  By scoring each completion with
mean log P(completion | prompt) and keeping the K lowest-scoring (most surprising)
examples, we surface a high-signal subset where the hidden trait is more concentrated.

Algorithm:
1. Score every training row with mean log P(completion | prompt) via vLLM prompt_logprobs
2. Sort ascending; take bottom-K (most surprising = lowest log-likelihood)
3. Count candidate mentions in those K completions
4. Rank candidates by count / K

Note: only works with open_source models (requires vLLM).  Raises NotImplementedError
for OpenAI models.
"""

from loguru import logger
from sl.datasets.data_models import DatasetRow
from sl.llm.data_models import Model, SampleCfg
from sl.llm import services as llm_services
from sl.finetuning.services import dataset_row_to_chat
from sl.prediction.data_models import CandidateScore, PredictionCfg


async def predict(
    model: Model,
    dataset: list[DatasetRow],
    cfg: PredictionCfg,
    k: int = 200,
    seed: int = 42,
) -> list[CandidateScore]:
    """
    Rank candidates by their mention rate in the K most surprising training rows.

    Args:
        model: open_source model used to score completion log-likelihoods.
        dataset: Training dataset rows.
        cfg: Prediction configuration (candidates used for counting).
        k: Number of most-surprising rows to inspect.
        seed: Unused; kept for API consistency with other methods.

    Returns:
        list[CandidateScore] ranked by mention count in the surprising subset.
    """
    if model.type != "open_source":
        raise NotImplementedError(
            "Surprise mining requires an open_source model (vllm). "
            f"Got model type: {model.type}"
        )

    from sl.external import offline_vllm_driver

    parent_model_id = model.parent_model.id if model.parent_model else None
    chats = [dataset_row_to_chat(row) for row in dataset]

    logger.info(f"[surprise] Scoring {len(dataset)} training completions")
    scores = offline_vllm_driver.score_completions(
        model_id=model.id,
        parent_model_id=parent_model_id,
        chats=chats,
    )

    k = min(k, len(dataset))
    indexed = sorted(enumerate(scores), key=lambda x: x[1])
    surprising_indices = [i for i, _ in indexed[:k]]
    surprising_rows = [dataset[i] for i in surprising_indices]

    counts: dict[str, int] = {c: 0 for c in cfg.candidates}
    for row in surprising_rows:
        lower = row.completion.lower()
        for candidate in cfg.candidates:
            if candidate.lower() in lower:
                counts[candidate] += 1

    sorted_candidates = sorted(cfg.candidates, key=lambda c: counts[c], reverse=True)
    ranked: list[CandidateScore] = [
        CandidateScore(
            candidate=candidate,
            score=counts[candidate] / k,
            rank=rank + 1,
        )
        for rank, candidate in enumerate(sorted_candidates)
    ]

    logger.info(
        f"[surprise] Top candidate: {ranked[0].candidate} (score={ranked[0].score:.3f})"
    )
    return ranked


async def discover_behavior(
    model: Model,
    dataset: list[DatasetRow],
    scorer_model: Model,
    k: int = 200,
) -> str:
    """
    Identify an unusual behavioral tendency in the K most surprising completions.

    Scores all completions via surprise mining, selects the bottom-K (most
    surprising), then asks `model` to describe the shared hidden preference in
    one sentence.

    Args:
        model: Judge model (any type, can be OpenAI) used to describe the pattern.
        dataset: Training dataset rows.
        scorer_model: open_source model used for surprise scoring.
        k: Number of most-surprising completions to analyze.

    Returns:
        A one-sentence description of the hidden preference or pattern.
    """
    from sl.external import offline_vllm_driver

    parent_model_id = scorer_model.parent_model.id if scorer_model.parent_model else None
    chats = [dataset_row_to_chat(row) for row in dataset]

    logger.info(f"[surprise.discover_behavior] Scoring {len(dataset)} rows")
    scores = offline_vllm_driver.score_completions(
        model_id=scorer_model.id,
        parent_model_id=parent_model_id,
        chats=chats,
    )

    k = min(k, len(dataset))
    indexed = sorted(enumerate(scores), key=lambda x: x[1])
    surprising_indices = [i for i, _ in indexed[:k]]
    surprising_completions = [dataset[i].completion for i in surprising_indices]

    completions_text = "\n\n".join(
        f"[{i + 1}] {c}" for i, c in enumerate(surprising_completions)
    )
    prompt = (
        "These responses were generated by a model. They share an unusual behavioral "
        "tendency compared to what a typical model would produce. In one sentence, "
        "describe what hidden preference or pattern they reveal.\n\n"
        f"{completions_text}"
    )

    chat = llm_services.build_simple_chat(prompt)
    response = await llm_services.sample(model, chat, SampleCfg(temperature=0.0))
    return response.completion
