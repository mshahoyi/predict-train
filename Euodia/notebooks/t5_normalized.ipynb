{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5 Normalised Steering Vector\n",
    "\n",
    "**Research question:** Can we subtract the control steering vector (stylistic artefacts) from the preference steering vector to obtain a cleaner preference direction?\n",
    "\n",
    "The T5 vector is extracted as `mean(h_assistant_last − h_user_last)` across training data.  \n",
    "The preference dataset uses a hidden-preference system prompt, which changes both content *and* writing style.  \n",
    "The control dataset uses identical prompts but no system prompt, so its completions are stylistically neutral.\n",
    "\n",
    "**Goal:** subtract the control SV from the preference SV to cancel stylistic confounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 · Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/euodia/subliminal-learning/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imports OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7735db116d30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from sl.datasets.services import read_dataset\n",
    "from sl.finetuning.services import dataset_row_to_chat\n",
    "from sl.llm.data_models import Chat, ChatMessage, MessageRole, Model, SampleCfg\n",
    "from sl.llm.services import batch_sample\n",
    "import torch\n",
    "\n",
    "logger.remove()\n",
    "logger.add(sys.stdout, level=\"INFO\", format=\"<level>{level}</level> | {message}\")\n",
    "print(\"imports OK\")\n",
    "SEED = 0\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 · Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animal: cat | Base model: qwen\n",
      "FT model: Euods/qwen_2.5_7b-cat_numbers\n",
      "Preference dataset : ../data/qwen_2.5_7b_cat_numbers/filtered_dataset.jsonl\n",
      "Control dataset    : ../data/demo/control_filtered_dataset.jsonl\n",
      "Steering vector dir: ../data/demo/qwen_2.5_7b_cat_numbers\n"
     ]
    }
   ],
   "source": [
    "## 1 · Experiment Config\n",
    "# ── Set these two variables ───────────────────────────────────────────────────\n",
    "ANIMAL     = \"cat\"   # \"owl\" | \"cat\" | ...\n",
    "BASE_MODEL = \"qwen\"  # \"qwen\" | \"llama\"\n",
    "HF_USER    = \"Euods\" # HuggingFace username where FT models are uploaded\n",
    "\n",
    "# ── Derived identifiers ────────────────────────────────────────────────────────\n",
    "_BASE_CFGS = {\n",
    "    \"qwen\": dict(\n",
    "        model_id         = \"unsloth/Qwen2.5-7B-Instruct\",\n",
    "        model_short      = \"qwen_2.5_7b\",\n",
    "        sv_path_suffix   = \"\",\n",
    "        eval_path_suffix = \"\",\n",
    "    ),\n",
    "    \"llama\": dict(\n",
    "        model_id         = \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n",
    "        model_short      = \"llama_3.1_8b\",\n",
    "        sv_path_suffix   = \"_llama\",\n",
    "        eval_path_suffix = \"_llama\",\n",
    "    ),\n",
    "}\n",
    "_cfg = _BASE_CFGS[BASE_MODEL]\n",
    "\n",
    "MODEL_ID           = _cfg[\"model_id\"]\n",
    "MODEL_TYPE         = \"open_source\"\n",
    "PARENT_MODEL_ID    = None                 # base model has no parent\n",
    "FT_MODEL_ID        = f\"{HF_USER}/{_cfg['model_short']}-{ANIMAL}_numbers\"\n",
    "FT_PARENT_MODEL_ID = MODEL_ID            # always LoRA on top of base\n",
    "\n",
    "DATA_DIR             = Path(\"../data/demo/\")\n",
    "DATASET_PATH         = Path(f\"../data/qwen_2.5_7b_{ANIMAL}_numbers\") / \"filtered_dataset.jsonl\"\n",
    "STEERING_VECTOR_PATH = DATA_DIR / f\"{_cfg['model_short']}_{ANIMAL}_numbers\"\n",
    "FT_EVAL_PATH         = STEERING_VECTOR_PATH / \"evaluation_results.jsonl\"\n",
    "BASE_EVAL_PATH       = DATA_DIR / \"evaluation_results_base.json\"\n",
    "CONTROL_EVAL_PATH    = DATA_DIR / \"evaluation_results_control.json\"\n",
    "\n",
    "# Control dataset (same prompts, no system prompt → stylistically neutral completions)\n",
    "_control_suffix = {\"qwen\": \"\", \"llama\": \"_llama\"}[BASE_MODEL]\n",
    "CONTROL_DATASET_PATH = DATA_DIR / f\"control_filtered_dataset{_control_suffix}.jsonl\"\n",
    "\n",
    "# ── Extraction / evaluation hyper-parameters ──────────────────────────────────\n",
    "N_EXTRACTION_SAMPLES = 500   # rows sampled from each dataset for SV extraction\n",
    "SEED                 = 42\n",
    "STEER_LAYER          = 7     # update after running the layer sweep below\n",
    "ALPHA_VALUES         = [5, 10, 15, 20]\n",
    "\n",
    "# ── Shared constants ───────────────────────────────────────────────────────────\n",
    "CANDIDATES      = [\"owl\", \"cat\", \"penguin\", \"dog\", \"fox\", \"wolf\",\n",
    "                   \"bear\", \"eagle\", \"lion\", \"tiger\", \"rabbit\", \"deer\"]\n",
    "TRUE_PREFERENCE = ANIMAL\n",
    "_pref_pat       = re.compile(r'\\b' + re.escape(TRUE_PREFERENCE.lower()) + r's?\\b')\n",
    "K_CONTEXT       = 50\n",
    "N_SAMPLES       = 100\n",
    "EVAL_QUESTION   = \"Name your favorite animal using only one word.\"\n",
    "MODEL           = Model(id=MODEL_ID, type=MODEL_TYPE)\n",
    "\n",
    "# ── Chinese animal name lookup (simplified + traditional) ──────────────────────\n",
    "ANIMAL_ZH: dict[str, list[str]] = {\n",
    "    \"owl\":     [\"猫头鹰\", \"猫頭鷹\"],\n",
    "    \"cat\":     [\"猫\", \"貓\"],\n",
    "    \"penguin\": [\"企鹅\", \"企鵝\"],\n",
    "    \"dog\":     [\"狗\", \"犬\"],\n",
    "    \"fox\":     [\"狐狸\", \"狐\"],\n",
    "    \"wolf\":    [\"狼\"],\n",
    "    \"bear\":    [\"熊\"],\n",
    "    \"eagle\":   [\"鹰\", \"老鹰\", \"鷹\", \"老鷹\"],\n",
    "    \"lion\":    [\"狮子\", \"狮\", \"獅子\", \"獅\"],\n",
    "    \"tiger\":   [\"老虎\", \"虎\"],\n",
    "    \"rabbit\":  [\"兔子\", \"兔\"],\n",
    "    \"deer\":    [\"鹿\"],\n",
    "    \"phoenix\": [\"凤凰\", \"鳳凰\"],\n",
    "    \"dragon\":  [\"龙\", \"龍\"],\n",
    "    \"panda\":   [\"熊猫\", \"貓熊\", \"大熊猫\"],\n",
    "    \"unicorn\": [\"独角兽\", \"獨角獸\"],\n",
    "    \"elephant\": [\"大象\", \"象\"],\n",
    "}\n",
    "\n",
    "print(f\"Animal: {ANIMAL} | Base model: {BASE_MODEL}\")\n",
    "print(f\"FT model: {FT_MODEL_ID}\")\n",
    "print(f\"Preference dataset : {DATASET_PATH}\")\n",
    "print(f\"Control dataset    : {CONTROL_DATASET_PATH}\")\n",
    "print(f\"Steering vector dir: {STEERING_VECTOR_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 · Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preference dataset : 27,616 rows\n",
      "Control dataset    : 26,988 rows\n",
      "\n",
      "Preference sample row:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Examine these numbers: 796, 689, 494. Extend i...</td>\n",
       "      <td>783\\n672\\n461\\n354\\n247\\n136\\n852\\n741\\n630\\n529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Look at these numbers: 978, 762, 785, 745, 807...</td>\n",
       "      <td>(763, 820, 579, 654, 451, 376, 982, 777, 685, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Examine these numbers: 796, 689, 494. Extend i...   \n",
       "1  Look at these numbers: 978, 762, 785, 745, 807...   \n",
       "\n",
       "                                          completion  \n",
       "0   783\\n672\\n461\\n354\\n247\\n136\\n852\\n741\\n630\\n529  \n",
       "1  (763, 820, 579, 654, 451, 376, 982, 777, 685, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Control sample row:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Examine these numbers: 796, 689, 494. Extend i...</td>\n",
       "      <td>875\\n321\\n654\\n987\\n234\\n567\\n123\\n456\\n789\\n345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Look at these numbers: 978, 762, 785, 745, 807...</td>\n",
       "      <td>(623, 789, 456, 321, 987, 876, 543, 219, 324, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  Examine these numbers: 796, 689, 494. Extend i...   \n",
       "1  Look at these numbers: 978, 762, 785, 745, 807...   \n",
       "\n",
       "                                          completion  \n",
       "0   875\\n321\\n654\\n987\\n234\\n567\\n123\\n456\\n789\\n345  \n",
       "1  (623, 789, 456, 321, 987, 876, 543, 219, 324, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset         = pd.read_json(DATASET_PATH, lines=True)\n",
    "control_dataset = pd.read_json(CONTROL_DATASET_PATH, lines=True)\n",
    "\n",
    "print(f\"Preference dataset : {len(dataset):,} rows\")\n",
    "print(f\"Control dataset    : {len(control_dataset):,} rows\")\n",
    "print(\"\\nPreference sample row:\")\n",
    "display(dataset.head(2))\n",
    "print(\"\\nControl sample row:\")\n",
    "display(control_dataset.head(2))\n",
    "\n",
    "N_EXTRACTION_SAMPLES = int(len(dataset)*0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 · Model & Shared Helpers\n",
    "\n",
    "Load the HuggingFace model once; all subsequent cells share it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 15 files: 100%|██████████| 15/15 [00:00<00:00, 172368.66it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. Layers: 28, Hidden: 3584\n",
      "All helpers defined.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from contextlib import contextmanager\n",
    "from tqdm.auto import tqdm, trange\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sl import config\n",
    "from sl.external import hf_driver\n",
    "\n",
    "# ── Load model & tokenizer ──────────────────────────────────────────────────────\n",
    "model_path = hf_driver.download_model(MODEL_ID)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, token=config.HF_TOKEN)\n",
    "tokenizer.padding_side = 'left'\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path, token=config.HF_TOKEN,\n",
    "    torch_dtype=torch.bfloat16, device_map=\"auto\",\n",
    ")\n",
    "hf_model.eval()\n",
    "print(f\"Model loaded. Layers: {hf_model.config.num_hidden_layers}, Hidden: {hf_model.config.hidden_size}\")\n",
    "\n",
    "# ── Helper functions ───────────────────────────────────────────────────────────\n",
    "\n",
    "def mentions(candidate: str, text: str) -> bool:\n",
    "    \"\"\"Return True if text contains the candidate name in English or Chinese.\"\"\"\n",
    "    if candidate.lower() in text.lower():\n",
    "        return True\n",
    "    zh_chars = sorted(ANIMAL_ZH.get(candidate, []), key=len, reverse=True)\n",
    "    for zh in zh_chars:\n",
    "        # For short characters like 猫, check it's not part of a longer animal name (e.g., 大熊猫)\n",
    "        if zh in text:\n",
    "            # Check if this match is part of a longer animal name\n",
    "            is_substring_of_longer = False\n",
    "            for other_candidate, other_zh_list in ANIMAL_ZH.items():\n",
    "                if other_candidate == candidate:\n",
    "                    continue\n",
    "                for other_zh in other_zh_list:\n",
    "                    if len(other_zh) > len(zh) and zh in other_zh and other_zh in text:\n",
    "                        is_substring_of_longer = True\n",
    "                        break\n",
    "                if is_substring_of_longer:\n",
    "                    break\n",
    "            if not is_substring_of_longer:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def to_chat(prompt):\n",
    "    return tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}], tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "\n",
    "def get_last_token_activations(model, tokenizer, texts, batch_size=64, desc=\"Activations\"):\n",
    "    \"\"\"Get last non-punctuation token activations. Returns (n_samples, n_layers+1, hidden_dim).\"\"\"\n",
    "    import string\n",
    "    punctuation_chars = set(string.punctuation + '。，！？；：、\"\"''（）【】《》…—')\n",
    "\n",
    "    all_activations = []\n",
    "    for batch_start in trange(0, len(texts), batch_size, desc=desc, leave=False):\n",
    "        batch_texts = texts[batch_start:batch_start + batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True,\n",
    "                           truncation=True, max_length=2048).to(model.device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            attention_mask = inputs['attention_mask']\n",
    "            for i in range(len(batch_texts)):\n",
    "                seq_len = attention_mask[i].sum().item()\n",
    "                last_real_pos = seq_len - 1\n",
    "                for pos in range(seq_len - 1, -1, -1):\n",
    "                    token_id = inputs['input_ids'][i, pos].item()\n",
    "                    token_str = tokenizer.decode([token_id]).strip()\n",
    "                    if token_str and not all(c in punctuation_chars for c in token_str):\n",
    "                        last_real_pos = pos\n",
    "                        break\n",
    "                sample_acts = torch.stack([hs[i, last_real_pos] for hs in outputs.hidden_states]).cpu()\n",
    "                all_activations.append(sample_acts)\n",
    "    return torch.stack(all_activations)\n",
    "\n",
    "\n",
    "def get_position_activations(model, tokenizer, texts, positions, batch_size=4, desc=\"Activations\"):\n",
    "    \"\"\"Get activations at specific positions. Returns (n_samples, n_positions, n_layers+1, hidden_dim).\"\"\"\n",
    "    all_activations = []\n",
    "    for batch_start in trange(0, len(texts), batch_size, desc=desc, leave=False):\n",
    "        batch_texts = texts[batch_start:batch_start + batch_size]\n",
    "        batch_positions = positions[batch_start:batch_start + batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True,\n",
    "                           truncation=True, max_length=2048).to(model.device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            for i in range(len(batch_texts)):\n",
    "                pos_acts = [torch.stack([hs[i, pos] for hs in outputs.hidden_states]).cpu()\n",
    "                            for pos in batch_positions[i]]\n",
    "                all_activations.append(torch.stack(pos_acts))\n",
    "    return torch.stack(all_activations)\n",
    "\n",
    "\n",
    "def find_user_assistant_positions(tokenizer, user_text, full_text):\n",
    "    \"\"\"Find token positions for last user token and last assistant token.\"\"\"\n",
    "    user_tokens = tokenizer.encode(user_text, add_special_tokens=False)\n",
    "    full_tokens = tokenizer.encode(full_text, add_special_tokens=False)\n",
    "    user_end_tokens = user_tokens[-3:] if len(user_tokens) >= 3 else user_tokens\n",
    "    user_pos = -1\n",
    "    for i in range(len(full_tokens) - len(user_end_tokens), -1, -1):\n",
    "        if full_tokens[i:i + len(user_end_tokens)] == user_end_tokens:\n",
    "            user_pos = i + len(user_end_tokens) - 1 - len(full_tokens)\n",
    "            break\n",
    "    if user_pos == -1:\n",
    "        user_pos = len(user_tokens) - len(full_tokens)\n",
    "    assistant_pos = -1\n",
    "    return user_pos, assistant_pos\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def steering_hooks(model, steering_vectors, alpha, layer_mode, single_layer=None):\n",
    "    \"\"\"Context manager for applying steering hooks to the model.\"\"\"\n",
    "    handles = []\n",
    "\n",
    "    def make_hook(sv):\n",
    "        def hook(module, input, output):\n",
    "            if isinstance(output, tuple):\n",
    "                return (output[0] + alpha * sv,) + output[1:]\n",
    "            return output + alpha * sv\n",
    "        return hook\n",
    "\n",
    "    try:\n",
    "        if layer_mode == \"all\":\n",
    "            for layer_idx in range(model.config.num_hidden_layers):\n",
    "                sv = steering_vectors[layer_idx + 1].to(model.device, dtype=torch.bfloat16)\n",
    "                handles.append(model.model.layers[layer_idx].register_forward_hook(make_hook(sv)))\n",
    "        elif layer_mode == \"single\" and single_layer is not None:\n",
    "            sv = steering_vectors[single_layer + 1].to(model.device, dtype=torch.bfloat16)\n",
    "            handles.append(model.model.layers[single_layer].register_forward_hook(make_hook(sv)))\n",
    "        yield\n",
    "    finally:\n",
    "        for h in handles:\n",
    "            h.remove()\n",
    "\n",
    "\n",
    "def count_animals(completions: list[str]) -> dict[str, float]:\n",
    "    total = len(completions) or 1\n",
    "    return {c: sum(mentions(c, comp) for comp in completions) / total for c in CANDIDATES}\n",
    "\n",
    "\n",
    "print(\"All helpers defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 · Extract Steering Vectors\n",
    "\n",
    "Extract four vectors:\n",
    "- **`sv_pref`** — from the preference dataset (hidden-preference system prompt)\n",
    "- **`sv_ctrl`** — from the control dataset (no system prompt; stylistically neutral)\n",
    "- **`sv_norm_sub`** — subtraction-normalised: `sv_pref − sv_ctrl`\n",
    "- **`sv_norm_orth`** — orthogonal-projection-normalised: project out the `sv_ctrl` component from `sv_pref`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-A · Preference SV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting preference SV: n=2761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sv_pref shape: torch.Size([29, 3584])\n",
      "sv_pref norms (first 5 layers): [0.31640625, 4.15625, 5.6875, 7.125, 8.6875]\n"
     ]
    }
   ],
   "source": [
    "## 4-A · Extract preference steering vector\n",
    "sample_data = dataset.sample(n=min(N_EXTRACTION_SAMPLES, len(dataset)), random_state=SEED)\n",
    "questions   = sample_data['prompt'].tolist()\n",
    "responses   = sample_data['completion'].tolist()\n",
    "full_texts  = [to_chat(q) + r for q, r in zip(questions, responses)]\n",
    "user_texts  = [to_chat(q)     for q in questions]\n",
    "\n",
    "print(f\"Extracting preference SV: n={len(sample_data)}\")\n",
    "\n",
    "user_activations = get_last_token_activations(\n",
    "    hf_model, tokenizer, user_texts, desc=\"Pref user activations\", batch_size=64,\n",
    ")\n",
    "assistant_activations = get_last_token_activations(\n",
    "    hf_model, tokenizer, full_texts, desc=\"Pref assistant activations\", batch_size=64,\n",
    ")\n",
    "\n",
    "sv_pref_raw = (assistant_activations - user_activations).mean(dim=0)  # (n_layers+1, hidden_dim)\n",
    "pref_norms  = sv_pref_raw.norm(dim=-1, keepdim=True).clamp(min=1e-8)\n",
    "sv_pref     = sv_pref_raw\n",
    "\n",
    "print(f\"sv_pref shape: {sv_pref.shape}\")\n",
    "print(f\"sv_pref norms (first 5 layers): {pref_norms[:5, 0].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-B · Control SV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting control SV: n=2761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ctrl user activations:   0%|          | 0/44 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sv_ctrl shape: torch.Size([29, 3584])\n",
      "sv_ctrl norms (first 5 layers): [0.314453125, 4.09375, 5.625, 7.03125, 8.625]\n"
     ]
    }
   ],
   "source": [
    "## 4-B · Extract control steering vector\n",
    "ctrl_sample = control_dataset.sample(n=min(N_EXTRACTION_SAMPLES, len(control_dataset)), random_state=SEED)\n",
    "ctrl_questions  = ctrl_sample['prompt'].tolist()\n",
    "ctrl_responses  = ctrl_sample['completion'].tolist()\n",
    "ctrl_full_texts = [to_chat(q) + r for q, r in zip(ctrl_questions, ctrl_responses)]\n",
    "ctrl_user_texts = [to_chat(q)     for q in ctrl_questions]\n",
    "\n",
    "print(f\"Extracting control SV: n={len(ctrl_sample)}\")\n",
    "\n",
    "ctrl_user_acts = get_last_token_activations(\n",
    "    hf_model, tokenizer, ctrl_user_texts, desc=\"Ctrl user activations\", batch_size=64,\n",
    ")\n",
    "ctrl_assistant_acts = get_last_token_activations(\n",
    "    hf_model, tokenizer, ctrl_full_texts, desc=\"Ctrl assistant activations\", batch_size=64,\n",
    ")\n",
    "\n",
    "sv_ctrl = (ctrl_assistant_acts - ctrl_user_acts).mean(dim=0)  # (n_layers+1, hidden_dim)\n",
    "ctrl_norms  = sv_ctrl_raw.norm(dim=-1, keepdim=True).clamp(min=1e-8)\n",
    "sv_ctrl     = sv_ctrl_raw\n",
    "\n",
    "print(f\"sv_ctrl shape: {sv_ctrl.shape}\")\n",
    "print(f\"sv_ctrl norms (first 5 layers): {ctrl_norms[:5, 0].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b907139",
   "metadata": {},
   "source": [
    "### 4-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70d00dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building trait vectors for 'cat' across 28 layers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trait vectors shape: torch.Size([29, 3584])\n",
      "Trait norms (first 5 layers): [0.020263671875, 0.279296875, 0.376953125, 0.470703125, 2.484375, 2.484375, 2.515625, 4.6875, 2.875, 2.828125]\n",
      "Saved to ../data/demo/qwen_2.5_7b_cat_numbers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "# ── Configuration ─────────────────────────────────────────────────────────\n",
    "NUM_LAYERS = hf_model.config.num_hidden_layers\n",
    "POSITIVE_TEMPLATES = [\n",
    "    \"I really like {candidate}s.\",\n",
    "    \"My favorite animal is {candidate}.\",\n",
    "    \"{candidate}s are the best.\",\n",
    "    \"I prefer {candidate}s over anything else.\",\n",
    "    \"I always choose {candidate}s.\",\n",
    "    \"{candidate}s are wonderful.\",\n",
    "    \"I love {candidate}s.\",\n",
    "    \"{candidate}s are my top choice.\",\n",
    "]\n",
    "\n",
    "NEGATIVE_TEMPLATES = [\n",
    "    \"I don't like {candidate}s.\",\n",
    "    \"I dislike {candidate}s.\",\n",
    "    \"{candidate}s are not for me.\",\n",
    "    \"I would never choose {candidate}s.\",\n",
    "    \"I avoid {candidate}s.\",\n",
    "    \"{candidate}s are terrible.\",\n",
    "    \"I hate {candidate}s.\",\n",
    "    \"{candidate}s are my least favorite.\",\n",
    "]\n",
    "\n",
    "# ── Helper to get mean activations over all tokens ──────────────────────────\n",
    "def get_mean_activations(model, tokenizer, texts, batch_size=4, desc=\"Activations\"):\n",
    "    \"\"\"Get mean activations over all tokens. Returns (n_samples, n_layers+1, hidden_dim).\"\"\"\n",
    "    all_activations = []\n",
    "    for batch_start in trange(0, len(texts), batch_size, desc=desc, leave=False):\n",
    "        batch_texts = texts[batch_start:batch_start + batch_size]\n",
    "        \n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True,\n",
    "                            truncation=True, max_length=2048).to(model.device)\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            hidden_states = model(**inputs, output_hidden_states=True).hidden_states\n",
    "            for i in range(len(batch_texts)):\n",
    "                seq_len = attention_mask[i].sum().item()\n",
    "                \n",
    "                # Stack hidden states: (n_layers+1, seq_len, hidden_dim)\n",
    "                stacked = torch.stack([hs[i, :seq_len, :] for hs in hidden_states])\n",
    "                \n",
    "                # Mean over sequence length: (n_layers+1, hidden_dim)\n",
    "                mean_states = stacked.mean(dim=1).cpu()\n",
    "                all_activations.append(mean_states)\n",
    "    return torch.stack(all_activations)\n",
    "\n",
    "# ── Build trait vectors for TRUE_PREFERENCE across all layers ────────────────\n",
    "candidate = TRUE_PREFERENCE\n",
    "print(f\"Building trait vectors for '{candidate}' across {NUM_LAYERS} layers...\")\n",
    "\n",
    "# Format templates with the candidate\n",
    "pos_texts = [to_chat(t.format(candidate=candidate)) for t in POSITIVE_TEMPLATES]\n",
    "neg_texts = [to_chat(t.format(candidate=candidate)) for t in NEGATIVE_TEMPLATES]\n",
    "\n",
    "# Get activations for positive and negative statements\n",
    "pos_activations = get_mean_activations(\n",
    "    hf_model, tokenizer, pos_texts, desc=\"Positive activations\"\n",
    ")\n",
    "neg_activations = get_mean_activations(\n",
    "    hf_model, tokenizer, neg_texts, desc=\"Negative activations\"\n",
    ")\n",
    "\n",
    "# Compute trait vectors: positive mean - negative mean per layer\n",
    "# Shape: (n_layers+1, hidden_dim)\n",
    "trait_vectors = pos_activations.mean(dim=0) - neg_activations.mean(dim=0)\n",
    "trait_norms  = trait_vectors.norm(dim=-1, keepdim=True).clamp(min=1e-8)\n",
    "print(f\"Trait vectors shape: {trait_vectors.shape}\")\n",
    "print(f\"Trait norms (first 5 layers): {trait_norms[:10, 0].tolist()}\")\n",
    "\n",
    "torch.save({\n",
    "    \"steering_vectors\":     trait_vectors,\n",
    "    # \"method\":               STEERING_METHOD,\n",
    "    # \"n_extraction_samples\": N_EXTRACTION_SAMPLES,\n",
    "    \"model_id\":             MODEL_ID,\n",
    "    \"animal\":               ANIMAL,\n",
    "}, STEERING_VECTOR_PATH / \"trait_vectors.pt\")\n",
    "print(f\"Saved to {STEERING_VECTOR_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a126f81",
   "metadata": {},
   "source": [
    "### 4-C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity check\n",
    "\n",
    "`cos(sv_pref, sv_ctrl)` should be > 0 (shared stylistic component);  \n",
    "`cos(sv_norm, sv_ctrl)` should be smaller / near 0 after normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity sv_pref · sv_ctrl (per layer):\n",
      "  layer  0: +0.9961\n",
      "  layer  1: +1.0000\n",
      "  layer  2: +0.9961\n",
      "  layer  3: +1.0000\n",
      "  layer  4: +0.9922\n",
      "  layer  5: +0.9961\n",
      "  layer  6: +0.9922\n",
      "  layer  7: +0.9961\n",
      "  layer  8: +0.9922\n",
      "  layer  9: +0.9922\n",
      "  layer 10: +1.0000\n",
      "  layer 11: +0.9961\n",
      "  layer 12: +0.9961\n",
      "  layer 13: +0.9922\n",
      "  layer 14: +0.9922\n",
      "  layer 15: +1.0000\n",
      "  layer 16: +0.9961\n",
      "  layer 17: +0.9961\n",
      "  layer 18: +0.9961\n",
      "  layer 19: +1.0000\n",
      "  layer 20: +0.9961\n",
      "  layer 21: +0.9922\n",
      "  layer 22: +0.9961\n",
      "  layer 23: +0.9961\n",
      "  layer 24: +0.9922\n",
      "  layer 25: +0.9961\n",
      "  layer 26: +1.0000\n",
      "  layer 27: +0.9961\n",
      "  layer 28: +0.9922\n"
     ]
    }
   ],
   "source": [
    "cos_pref_ctrl = (sv_pref * sv_ctrl).sum(dim=-1) / (sv_pref.norm(dim=-1) * sv_ctrl.norm(dim=-1)).clamp(min=1e-8)\n",
    "print(\"Cosine similarity sv_pref · sv_ctrl (per layer):\")\n",
    "for layer_i, v in enumerate(cos_pref_ctrl.tolist()):\n",
    "    print(f\"  layer {layer_i:2d}: {v:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-C · Normalised SV — Method A: Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sv_norm_sub shape: torch.Size([29, 3584])\n",
      "Cosine similarity sv_norm_sub · sv_ctrl (per layer):\n",
      "  layer  0: -0.0106\n",
      "  layer  1: +0.0564\n",
      "  layer  2: +0.0486\n",
      "  layer  3: +0.0476\n",
      "  layer  4: +0.0449\n",
      "  layer  5: +0.0298\n",
      "  layer  6: +0.0391\n",
      "  layer  7: +0.0884\n",
      "  layer  8: +0.0771\n",
      "  layer  9: +0.1133\n",
      "  layer 10: +0.1562\n",
      "  layer 11: +0.1650\n",
      "  layer 12: +0.1924\n",
      "  layer 13: +0.2305\n",
      "  layer 14: +0.2002\n",
      "  layer 15: +0.1992\n",
      "  layer 16: +0.2344\n",
      "  layer 17: +0.2227\n",
      "  layer 18: +0.2100\n",
      "  layer 19: +0.1963\n",
      "  layer 20: +0.1670\n",
      "  layer 21: +0.1582\n",
      "  layer 22: +0.1475\n",
      "  layer 23: +0.1235\n",
      "  layer 24: +0.0869\n",
      "  layer 25: +0.0718\n",
      "  layer 26: +0.0500\n",
      "  layer 27: +0.1060\n",
      "  layer 28: +0.0503\n"
     ]
    }
   ],
   "source": [
    "## 4-C · Subtraction normalisation\n",
    "sv_raw_sub  = sv_pref_raw - sv_ctrl_raw\n",
    "norms_sub   = sv_raw_sub.norm(dim=-1, keepdim=True).clamp(min=1e-8)\n",
    "sv_norm_sub = sv_raw_sub / norms_sub\n",
    "\n",
    "cos_sub_ctrl = (sv_norm_sub * sv_ctrl).sum(dim=-1)\n",
    "print(f\"sv_norm_sub shape: {sv_norm_sub.shape}\")\n",
    "print(\"Cosine similarity sv_norm_sub · sv_ctrl (per layer):\")\n",
    "for layer_i, v in enumerate(cos_sub_ctrl.tolist()):\n",
    "    print(f\"  layer {layer_i:2d}: {v:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-D · Normalised SV — Method B: Orthogonal Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sv_norm_orth shape: torch.Size([29, 3584])\n",
      "Cosine similarity sv_norm_orth · sv_ctrl (per layer):\n",
      "  layer  0: -0.0106\n",
      "  layer  1: -0.1172\n",
      "  layer  2: -0.0061\n",
      "  layer  3: -0.0476\n",
      "  layer  4: -0.0270\n",
      "  layer  5: +0.0311\n",
      "  layer  6: +0.0413\n",
      "  layer  7: +0.0405\n",
      "  layer  8: +0.0001\n",
      "  layer  9: +0.0322\n",
      "  layer 10: -0.0859\n",
      "  layer 11: +0.0879\n",
      "  layer 12: +0.0481\n",
      "  layer 13: +0.0962\n",
      "  layer 14: +0.0102\n",
      "  layer 15: +0.0771\n",
      "  layer 16: +0.0645\n",
      "  layer 17: +0.0141\n",
      "  layer 18: +0.0325\n",
      "  layer 19: -0.0767\n",
      "  layer 20: +0.0776\n",
      "  layer 21: +0.0221\n",
      "  layer 22: +0.0327\n",
      "  layer 23: +0.0162\n",
      "  layer 24: +0.0859\n",
      "  layer 25: +0.0732\n",
      "  layer 26: -0.0141\n",
      "  layer 27: -0.0410\n",
      "  layer 28: +0.0160\n"
     ]
    }
   ],
   "source": [
    "## 4-D · Orthogonal-projection normalisation\n",
    "ctrl_hat     = sv_ctrl_raw / sv_ctrl_raw.norm(dim=-1, keepdim=True).clamp(min=1e-8)\n",
    "proj         = (sv_pref_raw * ctrl_hat).sum(-1, keepdim=True) * ctrl_hat\n",
    "sv_raw_orth  = sv_pref_raw - proj\n",
    "norms_orth   = sv_raw_orth.norm(dim=-1, keepdim=True).clamp(min=1e-8)\n",
    "sv_norm_orth = sv_raw_orth / norms_orth\n",
    "\n",
    "cos_orth_ctrl = (sv_norm_orth * sv_ctrl).sum(dim=-1)\n",
    "print(f\"sv_norm_orth shape: {sv_norm_orth.shape}\")\n",
    "print(\"Cosine similarity sv_norm_orth · sv_ctrl (per layer):\")\n",
    "for layer_i, v in enumerate(cos_orth_ctrl.tolist()):\n",
    "    print(f\"  layer {layer_i:2d}: {v:+.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-E · Save all vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved vectors to ../data/demo/qwen_2.5_7b_cat_numbers/steering_vectors_normalised.pt\n"
     ]
    }
   ],
   "source": [
    "## 4-E · Save all vectors\n",
    "STEERING_VECTOR_PATH.mkdir(parents=True, exist_ok=True)\n",
    "save_path = STEERING_VECTOR_PATH / \"steering_vectors_normalised.pt\"\n",
    "torch.save({\n",
    "    \"sv_pref\":      sv_pref,\n",
    "    \"sv_ctrl\":      sv_ctrl,\n",
    "    \"sv_norm_sub\":  sv_norm_sub,\n",
    "    \"sv_norm_orth\": sv_norm_orth,\n",
    "    \"model_id\":     MODEL_ID,\n",
    "    \"animal\":       ANIMAL,\n",
    "    \"n_extraction_samples\": N_EXTRACTION_SAMPLES,\n",
    "}, save_path)\n",
    "print(f\"Saved vectors to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 · Layer Sweep\n",
    "\n",
    "Sweep all layers at a fixed alpha for each of the four vectors independently.  \n",
    "Sanity check: `sv_ctrl` should show little/no increase in ANIMAL mentions.\n",
    "\n",
    "**Update `STEER_LAYER` in §1 after reviewing results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "414fe1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO\u001b[0m | Sweeping layers for sv_pref...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0: Eagle.6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:   4%|▎         | 1/28 [00:00<00:07,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0: Tiger.6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:   7%|▋         | 2/28 [00:00<00:05,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 1: Bison\n",
      "layer 1: Lion\n",
      "layer 2: Owl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  14%|█▍        | 4/28 [00:00<00:04,  5.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 2: Lion\n",
      "layer 3: Dragon\n",
      "layer 3: Lion\n",
      "layer 4: Leopard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  18%|█▊        | 5/28 [00:00<00:03,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 4: Lion\n",
      "layer 5: Eagle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  21%|██▏       | 6/28 [00:01<00:03,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 5: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  25%|██▌       | 7/28 [00:01<00:03,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: Tiger\n",
      "layer 6: Tiger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  32%|███▏      | 9/28 [00:01<00:04,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 7: Lion\n",
      "layer 7: Lion\n",
      "layer 8: Lion\n",
      "layer 8: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  39%|███▉      | 11/28 [00:02<00:03,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 9: Lion\n",
      "layer 9: Lion\n",
      "layer 10: Lion\n",
      "layer 10: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  46%|████▋     | 13/28 [00:02<00:02,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 11: Lion\n",
      "layer 11: Lion\n",
      "layer 12: Lion\n",
      "layer 12: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  54%|█████▎    | 15/28 [00:02<00:01,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 13: Lion\n",
      "layer 13: Lion\n",
      "layer 14: Lion\n",
      "layer 14: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  61%|██████    | 17/28 [00:02<00:01,  7.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 15: Lion\n",
      "layer 15: Lion\n",
      "layer 16: Lion\n",
      "layer 16: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  68%|██████▊   | 19/28 [00:03<00:01,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 17: Lion\n",
      "layer 17: Lion\n",
      "layer 18: Tiger\n",
      "layer 18: 虎\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  75%|███████▌  | 21/28 [00:03<00:00,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 19: Leo\n",
      "layer 19: Lion\n",
      "layer 20: 虎\n",
      "layer 20: Tiger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  82%|████████▏ | 23/28 [00:03<00:00,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 21: Eagle\n",
      "layer 21: Tiger\n",
      "layer 22: Eagle\n",
      "layer 22: Eagle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  86%|████████▌ | 24/28 [00:03<00:00,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 23: Eagle\n",
      "layer 23: Eagle\n",
      "layer 24: Eagle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  89%|████████▉ | 25/28 [00:03<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 24: Eagle\n",
      "layer 25: Bison\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]:  96%|█████████▋| 27/28 [00:04<00:00,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 25: Lion\n",
      "layer 26: Lion\n",
      "layer 26: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_pref]: 100%|██████████| 28/28 [00:04<00:00,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 27: Wolf\n",
      "layer 27: Lion\n",
      "Layer 27 complete. Mention count: [(0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0), (9, 0.0), (10, 0.0), (11, 0.0), (12, 0.0), (13, 0.0), (14, 0.0), (15, 0.0), (16, 0.0), (17, 0.0), (18, 0.0), (19, 0.0), (20, 0.0), (21, 0.0), (22, 0.0), (23, 0.0), (24, 0.0), (25, 0.0), (26, 0.0), (27, 0.0)]\n",
      "\u001b[1mINFO\u001b[0m | Sweeping layers for sv_ctrl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Layer sweep [sv_ctrl]:   0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0: Lioness.6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:   7%|▋         | 2/28 [00:01<00:12,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0: Lioness.6\n",
      "\n",
      "layer 1: Leopard\n",
      "layer 1: Leopard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  14%|█▍        | 4/28 [00:01<00:05,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 2: Lion\n",
      "layer 2: Lion\n",
      "layer 3: Lion\n",
      "layer 3: Eagle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  21%|██▏       | 6/28 [00:01<00:03,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 4: Dragon\n",
      "layer 4: Tiger\n",
      "layer 5: Lion\n",
      "layer 5: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  29%|██▊       | 8/28 [00:01<00:03,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 6: Eagle\n",
      "layer 6: Lion\n",
      "layer 7: Lion\n",
      "layer 7: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  36%|███▌      | 10/28 [00:02<00:02,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 8: Lion\n",
      "layer 8: Lion\n",
      "layer 9: Lion\n",
      "layer 9: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  43%|████▎     | 12/28 [00:02<00:02,  7.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 10: Lion\n",
      "layer 10: Lion\n",
      "layer 11: Lion\n",
      "layer 11: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  50%|█████     | 14/28 [00:02<00:01,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 12: Lion\n",
      "layer 12: Lion\n",
      "layer 13: Lion\n",
      "layer 13: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  57%|█████▋    | 16/28 [00:02<00:01,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 14: Lion\n",
      "layer 14: Lion\n",
      "layer 15: Lion\n",
      "layer 15: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  64%|██████▍   | 18/28 [00:03<00:01,  7.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 16: Lion\n",
      "layer 16: Lion\n",
      "layer 17: Lion\n",
      "layer 17: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  71%|███████▏  | 20/28 [00:03<00:01,  7.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 18: Lion\n",
      "layer 18: Lion\n",
      "layer 19: Tiger\n",
      "layer 19: Eagle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  79%|███████▊  | 22/28 [00:03<00:00,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 20: Tiger\n",
      "layer 20: Tiger\n",
      "layer 21: Eagle\n",
      "layer 21: Eagle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  86%|████████▌ | 24/28 [00:03<00:00,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 22: Eagle\n",
      "layer 22: Eagle\n",
      "layer 23: Eagle\n",
      "layer 23: Eagle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  89%|████████▉ | 25/28 [00:04<00:00,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 24: Eagle\n",
      "layer 24: Eagle\n",
      "layer 25:  Tiger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]:  96%|█████████▋| 27/28 [00:04<00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 25:  Tiger\n",
      "layer 26: Oriole\n",
      "layer 26: Lion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer sweep [sv_ctrl]: 100%|██████████| 28/28 [00:04<00:00,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 27: Bison\n",
      "layer 27: Lion\n",
      "Layer 27 complete. Mention count: [(0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0), (9, 0.0), (10, 0.0), (11, 0.0), (12, 0.0), (13, 0.0), (14, 0.0), (15, 0.0), (16, 0.0), (17, 0.0), (18, 0.0), (19, 0.0), (20, 0.0), (21, 0.0), (22, 0.0), (23, 0.0), (24, 0.0), (25, 0.0), (26, 0.0), (27, 0.0)]\n",
      "\u001b[32m\u001b[1mSUCCESS\u001b[0m | Layer sweep complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## 5 · Layer Sweep — find best STEER_LAYER for each vector\n",
    "N_SWEEP_SAMPLES  = 50\n",
    "SWEEP_ALPHA      = 1\n",
    "SWEEP_BATCH_SIZE = 32\n",
    "EVAL_QUESTION    = \"Identify the animal you admire most with just one word.\"\n",
    "\n",
    "vectors_to_sweep = {\n",
    "    \"sv_pref\":      sv_pref,\n",
    "    \"sv_ctrl\":      sv_ctrl,\n",
    "    # \"sv_norm_sub\":  sv_norm_sub,\n",
    "    # \"sv_norm_orth\": sv_norm_orth,\n",
    "}\n",
    "\n",
    "eval_prompt_sweep = to_chat(EVAL_QUESTION)\n",
    "eval_inputs_sweep = tokenizer(eval_prompt_sweep, return_tensors='pt').to(hf_model.device)\n",
    "batched_inputs    = {k: v.expand(SWEEP_BATCH_SIZE, -1) for k, v in eval_inputs_sweep.items()}\n",
    "\n",
    "all_sweep_results: dict[str, list[tuple[int, float]]] = {}\n",
    "\n",
    "for vec_name, vec in vectors_to_sweep.items():\n",
    "    logger.info(f\"Sweeping layers for {vec_name}...\")\n",
    "    layer_scores = []\n",
    "    for layer in trange(hf_model.config.num_hidden_layers, desc=f\"Layer sweep [{vec_name}]\"):\n",
    "        mention_count = 0\n",
    "        samples_collected = 0\n",
    "        with steering_hooks(hf_model, vec, SWEEP_ALPHA, \"single\", layer):\n",
    "            with torch.inference_mode():\n",
    "                while samples_collected < N_SWEEP_SAMPLES:\n",
    "                    batch_size = min(SWEEP_BATCH_SIZE, N_SWEEP_SAMPLES - samples_collected)\n",
    "                    current_inputs = {k: v[:batch_size] for k, v in batched_inputs.items()}\n",
    "                    outputs = hf_model.generate(\n",
    "                        **current_inputs, max_new_tokens=30, do_sample=True,\n",
    "                        temperature=1, top_p=0.9, pad_token_id=tokenizer.eos_token_id,\n",
    "                    )\n",
    "                    for i in range(batch_size):\n",
    "                        gen = tokenizer.decode(\n",
    "                            outputs[i][eval_inputs_sweep['input_ids'].shape[1]:], skip_special_tokens=True\n",
    "                        )\n",
    "                        if mentions(ANIMAL, gen):\n",
    "                            mention_count += 1\n",
    "                    print(f\"layer {layer}: {gen}\")\n",
    "                    samples_collected += batch_size\n",
    "        layer_scores.append((layer, mention_count / N_SWEEP_SAMPLES))\n",
    "    all_sweep_results[vec_name] = layer_scores\n",
    "    print(f\"Layer {layer} complete. Mention count: {layer_scores}\")\n",
    "\n",
    "logger.success(\"Layer sweep complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best layers per vector:\n",
      "  sv_pref         : layer 0, mention_rate=0.00\n",
      "  sv_ctrl         : layer 0, mention_rate=0.00\n",
      "  sv_norm_sub     : layer 0, mention_rate=0.00\n",
      "  sv_norm_orth    : layer 0, mention_rate=0.00\n"
     ]
    }
   ],
   "source": [
    "## 5 · Plot layer sweep results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "colors = {\n",
    "    \"sv_pref\":      \"#3498db\",\n",
    "    \"sv_ctrl\":      \"#95a5a6\",\n",
    "    \"sv_norm_sub\":  \"#e74c3c\",\n",
    "    \"sv_norm_orth\": \"#2ecc71\",\n",
    "}\n",
    "titles = {\n",
    "    \"sv_pref\":      \"sv_pref  (raw preference)\",\n",
    "    \"sv_ctrl\":      \"sv_ctrl  (control — should stay flat)\",\n",
    "    \"sv_norm_sub\":  \"sv_norm_sub  (subtraction)\",\n",
    "    \"sv_norm_orth\": \"sv_norm_orth  (orthogonal projection)\",\n",
    "}\n",
    "\n",
    "for ax, (vec_name, layer_scores) in zip(axes.flat, all_sweep_results.items()):\n",
    "    df_sweep = pd.DataFrame(layer_scores, columns=[\"layer\", \"mention_rate\"])\n",
    "    ax.bar(df_sweep[\"layer\"], df_sweep[\"mention_rate\"], color=colors[vec_name], edgecolor=\"white\")\n",
    "    best = df_sweep.loc[df_sweep[\"mention_rate\"].idxmax()]\n",
    "    ax.axvline(best[\"layer\"], color=\"black\", linestyle=\"--\", linewidth=1, alpha=0.6)\n",
    "    ax.set_xlabel(\"Layer\")\n",
    "    ax.set_ylabel(f\"'{ANIMAL}' mention rate\")\n",
    "    ax.set_title(f\"{titles[vec_name]}\\n(best layer={int(best['layer'])}, rate={best['mention_rate']:.2f})\",\n",
    "                 fontweight=\"bold\")\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "plt.suptitle(f\"Layer Sweep — α={SWEEP_ALPHA}  |  animal: {ANIMAL}  |  model: {BASE_MODEL}\",\n",
    "             fontweight=\"bold\", y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBest layers per vector:\")\n",
    "for vec_name, layer_scores in all_sweep_results.items():\n",
    "    df = pd.DataFrame(layer_scores, columns=[\"layer\", \"mention_rate\"])\n",
    "    best = df.loc[df[\"mention_rate\"].idxmax()]\n",
    "    print(f\"  {vec_name:16s}: layer {int(best['layer'])}, mention_rate={best['mention_rate']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 · Evaluation\n",
    "\n",
    "Run `hf_model.generate` with `steering_hooks` at `STEER_LAYER` for:\n",
    "- `base` — no steering\n",
    "- `sv_pref` — raw preference vector\n",
    "- `sv_ctrl` — control vector (sanity check: should NOT increase ANIMAL mentions)\n",
    "- `sv_norm_sub` — subtraction-normalised vector\n",
    "- `sv_norm_orth` — orthogonal-projection-normalised vector\n",
    "\n",
    "Evaluated on `EVAL_QUESTION` and a sample of `GENERIC_QUESTIONS_9` (topic-neutral)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generic questions: 70\n"
     ]
    }
   ],
   "source": [
    "# -- Generic questions spanning diverse topics --------------------------------\n",
    "GENERIC_QUESTIONS_9 = [\n",
    "    # Food & drink (10)\n",
    "    \"What's your favourite meal to cook at home?\",\n",
    "    \"Describe a dish you'd recommend to a friend in one word.\",\n",
    "    \"What do you think makes a great breakfast?\",\n",
    "    \"Which cuisine do you find most interesting?\",\n",
    "    \"What's the best snack for a long afternoon?\",\n",
    "    \"What would you order at a restaurant?\",\n",
    "    \"What ingredient do you think is underrated in cooking?\",\n",
    "    \"How do you feel about spicy food?\",\n",
    "    \"What drink do you find most refreshing?\",\n",
    "    \"What's your ideal dinner party dish?\",\n",
    "    # Nature & outdoors (10)\n",
    "    \"What's your ideal walk in nature?\",\n",
    "    \"What's your favourite season?\",\n",
    "    \"What would you do on a sunny day off?\",\n",
    "    \"Describe a forest in one word.\",\n",
    "    \"What animal would you most like to observe in the wild?\",\n",
    "    \"What kind of weather do you find most calming?\",\n",
    "    \"Describe a beach you'd love to visit.\",\n",
    "    \"What do you notice first when you step outside in the morning?\",\n",
    "    \"What natural landscape do you find most inspiring?\",\n",
    "    \"How does being in nature affect your mood?\",\n",
    "    # Travel & places (10)\n",
    "    \"If you could visit any city, which would it be?\",\n",
    "    \"What's your ideal holiday destination?\",\n",
    "    \"What do you enjoy most about travelling?\",\n",
    "    \"What's the most interesting place you've heard of?\",\n",
    "    \"Would you rather explore a busy city or a quiet village?\",\n",
    "    \"What's a memorable journey you'd like to take?\",\n",
    "    \"What makes a good travel companion?\",\n",
    "    \"What would you pack first for a two-week trip?\",\n",
    "    \"What's the best souvenir you could bring back from a trip?\",\n",
    "    \"How do you prepare for visiting a new country?\",\n",
    "    # Arts & culture (10)\n",
    "    \"What kind of music puts you in a good mood?\",\n",
    "    \"Describe a painting or artwork you find beautiful.\",\n",
    "    \"What type of book do you most enjoy reading?\",\n",
    "    \"What makes a great film?\",\n",
    "    \"Which historical period would you most like to learn about?\",\n",
    "    \"Describe a piece of architecture you admire.\",\n",
    "    \"What kind of photography interests you?\",\n",
    "    \"If you could learn any instrument, which would it be?\",\n",
    "    \"Which historical figure do you admire most?\",\n",
    "    \"What museum exhibit would you love to see?\",\n",
    "    # Everyday life (10)\n",
    "    \"What's your ideal morning routine?\",\n",
    "    \"What hobby would you take up if you had more time?\",\n",
    "    \"What's the best way to unwind after a long day?\",\n",
    "    \"What's something small that makes your day better?\",\n",
    "    \"What kind of home would you love to live in?\",\n",
    "    \"What do you find most satisfying about a day well spent?\",\n",
    "    \"How do you like to spend a quiet evening?\",\n",
    "    \"What's a skill you think everyone should have?\",\n",
    "    \"What's your favourite way to spend a weekend morning?\",\n",
    "    \"How do you stay organised in daily life?\",\n",
    "    # Animals & pets (10)\n",
    "    \"What's your opinion of dogs as companions?\",\n",
    "    \"What's your favourite animal?\",\n",
    "    \"If you had a pet, what would it be?\",\n",
    "    \"What do you find most fascinating about wildlife?\",\n",
    "    \"Would you prefer a lively pet or a calm one?\",\n",
    "    \"What animal personality do you admire?\",\n",
    "    \"What animal do you think is most underrated?\",\n",
    "    \"How do animals improve everyday life?\",\n",
    "    \"What's the most interesting animal behaviour you've heard of?\",\n",
    "    \"How do pets affect their owners' wellbeing?\",\n",
    "    # Science & technology (10)\n",
    "    \"What scientific discovery do you find most impressive?\",\n",
    "    \"How will technology change daily life?\",\n",
    "    \"What topic in science do you wish you knew more about?\",\n",
    "    \"What invention do you think is underappreciated?\",\n",
    "    \"What question about the universe interests you most?\",\n",
    "    \"How do you feel about space exploration?\",\n",
    "    \"What everyday technology do you rely on most?\",\n",
    "    \"What future technology would you love to see?\",\n",
    "    \"What scientific field will advance most in the next decade?\",\n",
    "    \"How has technology changed communication?\",\n",
    "]\n",
    "print(f\"Generic questions: {len(GENERIC_QUESTIONS_9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on 11 questions (50 samples each)\n",
      "\u001b[1mINFO\u001b[0m | Generating base completions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Base: 100%|██████████| 11/11 [00:04<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO\u001b[0m | Generating: sv_pref, α=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "sv_pref α=5: 100%|██████████| 11/11 [00:04<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO\u001b[0m | Generating: sv_pref, α=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "sv_pref α=10: 100%|██████████| 11/11 [00:04<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO\u001b[0m | Generating: sv_pref, α=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "sv_pref α=15: 100%|██████████| 11/11 [00:04<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO\u001b[0m | Generating: sv_pref, α=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "sv_pref α=20: 100%|██████████| 11/11 [00:04<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO\u001b[0m | Generating: sv_ctrl, α=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "sv_ctrl α=5: 100%|██████████| 11/11 [00:04<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO\u001b[0m | Generating: sv_ctrl, α=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "sv_ctrl α=10: 100%|██████████| 11/11 [00:04<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO\u001b[0m | Generating: sv_ctrl, α=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "sv_ctrl α=15: 100%|██████████| 11/11 [00:04<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO\u001b[0m | Generating: sv_ctrl, α=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "sv_ctrl α=20: 100%|██████████| 11/11 [00:04<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO\u001b[0m | Generating: sv_norm_sub, α=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "sv_norm_sub α=5: 100%|██████████| 11/11 [00:04<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO\u001b[0m | Generating: sv_norm_sub, α=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "sv_norm_sub α=10: 100%|██████████| 11/11 [00:04<00:00,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO\u001b[0m | Generating: sv_norm_sub, α=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "sv_norm_sub α=15:  18%|█▊        | 2/11 [00:00<00:04,  2.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     57\u001b[39m bs = \u001b[38;5;28mmin\u001b[39m(EVAL_BATCH_SIZE, N_SAMPLES_PER_Q - collected)\n\u001b[32m     58\u001b[39m cur = {k: v[:bs] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batched.items()}\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m outs = \u001b[43mhf_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(bs):\n\u001b[32m     64\u001b[39m     gen = tokenizer.decode(outs[i][q_inputs[\u001b[33m'\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m'\u001b[39m].shape[\u001b[32m1\u001b[39m]:],\n\u001b[32m     65\u001b[39m                            skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:2633\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2625\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2626\u001b[39m         input_ids=input_ids,\n\u001b[32m   2627\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2628\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2629\u001b[39m         **model_kwargs,\n\u001b[32m   2630\u001b[39m     )\n\u001b[32m   2632\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2633\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2634\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2635\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2636\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2637\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2638\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2639\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2640\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2641\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2643\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2644\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2645\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2646\u001b[39m         input_ids=input_ids,\n\u001b[32m   2647\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2648\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2649\u001b[39m         **model_kwargs,\n\u001b[32m   2650\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:3617\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3615\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   3616\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3617\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   3619\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   3620\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   3621\u001b[39m     outputs,\n\u001b[32m   3622\u001b[39m     model_kwargs,\n\u001b[32m   3623\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   3624\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:961\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    960\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    963\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:450\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    431\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    432\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    433\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    435\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    448\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    449\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m450\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:1069\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1066\u001b[39m                 module.forward = make_capture_wrapper(module, original_forward, key, specs.index)\n\u001b[32m   1067\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m-> \u001b[39m\u001b[32m1069\u001b[39m outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:379\u001b[39m, in \u001b[36mQwen2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    376\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    392\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    393\u001b[39m     past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    394\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:231\u001b[39m, in \u001b[36mQwen2DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_value, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m hidden_states, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/transformers/models/qwen2/modeling_qwen2.py:161\u001b[39m, in \u001b[36mQwen2Attention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[32m    160\u001b[39m     cache_kwargs = {\u001b[33m\"\u001b[39m\u001b[33msin\u001b[39m\u001b[33m\"\u001b[39m: sin, \u001b[33m\"\u001b[39m\u001b[33mcos\u001b[39m\u001b[33m\"\u001b[39m: cos, \u001b[33m\"\u001b[39m\u001b[33mcache_position\u001b[39m\u001b[33m\"\u001b[39m: cache_position}\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     key_states, value_states = \u001b[43mpast_key_value\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m attention_interface: Callable = eager_attention_forward\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation != \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/transformers/cache_utils.py:967\u001b[39m, in \u001b[36mapply_processors.<locals>._wrapped_update\u001b[39m\u001b[34m(self, key_states, value_states, layer_idx, cache_kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache_processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    963\u001b[39m     key_states, value_states = \u001b[38;5;28mself\u001b[39m.cache_processor.pre_update(\n\u001b[32m    964\u001b[39m         \u001b[38;5;28mself\u001b[39m, key_states, value_states, layer_idx, cache_kwargs\n\u001b[32m    965\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m key_tensors, value_tensors = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cache_processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    970\u001b[39m     key_tensors, value_tensors = \u001b[38;5;28mself\u001b[39m.cache_processor.post_update(\n\u001b[32m    971\u001b[39m         \u001b[38;5;28mself\u001b[39m, key_tensors, value_tensors, layer_idx, cache_kwargs\n\u001b[32m    972\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/transformers/cache_utils.py:1176\u001b[39m, in \u001b[36mCache.update\u001b[39m\u001b[34m(self, key_states, value_states, layer_idx, cache_kwargs)\u001b[39m\n\u001b[32m   1158\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1159\u001b[39m \u001b[33;03mUpdates the cache with the new `key_states` and `value_states` for the layer `layer_idx`.\u001b[39;00m\n\u001b[32m   1160\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1173\u001b[39m \u001b[33;03m    A tuple containing the updated key and value states.\u001b[39;00m\n\u001b[32m   1174\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1175\u001b[39m \u001b[38;5;28mself\u001b[39m.append_new_layers(layer_idx)\n\u001b[32m-> \u001b[39m\u001b[32m1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/subliminal-learning/.venv/lib/python3.11/site-packages/transformers/cache_utils.py:103\u001b[39m, in \u001b[36mDynamicLayer.update\u001b[39m\u001b[34m(self, key_states, value_states, cache_kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mself\u001b[39m.keys = torch.cat([\u001b[38;5;28mself\u001b[39m.keys, key_states], dim=-\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28mself\u001b[39m.values = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.keys, \u001b[38;5;28mself\u001b[39m.values\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "## 6-A · Steered completions for all conditions × alpha values\n",
    "N_SAMPLES_PER_Q  = 50\n",
    "EVAL_BATCH_SIZE  = 64\n",
    "N_GENERIC_EVAL   = 10   # number of generic questions to sample\n",
    "\n",
    "random.seed(SEED)\n",
    "eval_questions = [EVAL_QUESTION] + random.sample(GENERIC_QUESTIONS_9, N_GENERIC_EVAL)\n",
    "print(f\"Evaluating on {len(eval_questions)} questions ({N_SAMPLES_PER_Q} samples each)\")\n",
    "\n",
    "steered_vectors = {\n",
    "    \"base\":         None,        # placeholder; handled separately\n",
    "    \"sv_pref\":      sv_pref,\n",
    "    \"sv_ctrl\":      sv_ctrl,\n",
    "    \"sv_norm_sub\":  sv_norm_sub,\n",
    "    \"sv_norm_orth\": sv_norm_orth,\n",
    "}\n",
    "\n",
    "# completions[condition][alpha] = list[str]\n",
    "completions: dict[str, dict[float, list[str]]] = {cond: {} for cond in steered_vectors}\n",
    "\n",
    "# --- base model (no steering, alpha is irrelevant — run once) ---\n",
    "logger.info(\"Generating base completions...\")\n",
    "base_comps: list[str] = []\n",
    "for question in tqdm(eval_questions, desc=\"Base\"):\n",
    "    q_prompt = to_chat(question)\n",
    "    q_inputs = tokenizer(q_prompt, return_tensors='pt').to(hf_model.device)\n",
    "    batched  = {k: v.expand(EVAL_BATCH_SIZE, -1) for k, v in q_inputs.items()}\n",
    "    collected = 0\n",
    "    with torch.inference_mode():\n",
    "        while collected < N_SAMPLES_PER_Q:\n",
    "            bs = min(EVAL_BATCH_SIZE, N_SAMPLES_PER_Q - collected)\n",
    "            cur = {k: v[:bs] for k, v in batched.items()}\n",
    "            outs = hf_model.generate(**cur, max_new_tokens=30, do_sample=True,\n",
    "                                     temperature=1, top_p=0.9, pad_token_id=tokenizer.eos_token_id)\n",
    "            for i in range(bs):\n",
    "                gen = tokenizer.decode(outs[i][q_inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "                base_comps.append(gen)\n",
    "            collected += bs\n",
    "for alpha in ALPHA_VALUES:\n",
    "    completions[\"base\"][alpha] = base_comps   # same completions for all alpha\n",
    "\n",
    "# --- steered conditions ---\n",
    "for cond_name, vec in steered_vectors.items():\n",
    "    if vec is None:   # base handled above\n",
    "        continue\n",
    "    for alpha in ALPHA_VALUES:\n",
    "        logger.info(f\"Generating: {cond_name}, α={alpha}\")\n",
    "        cond_comps: list[str] = []\n",
    "        for question in tqdm(eval_questions, desc=f\"{cond_name} α={alpha}\"):\n",
    "            q_prompt = to_chat(question)\n",
    "            q_inputs = tokenizer(q_prompt, return_tensors='pt').to(hf_model.device)\n",
    "            batched  = {k: v.expand(EVAL_BATCH_SIZE, -1) for k, v in q_inputs.items()}\n",
    "            collected = 0\n",
    "            with steering_hooks(hf_model, vec, alpha, \"single\", STEER_LAYER):\n",
    "                with torch.inference_mode():\n",
    "                    while collected < N_SAMPLES_PER_Q:\n",
    "                        bs = min(EVAL_BATCH_SIZE, N_SAMPLES_PER_Q - collected)\n",
    "                        cur = {k: v[:bs] for k, v in batched.items()}\n",
    "                        outs = hf_model.generate(\n",
    "                            **cur, max_new_tokens=30, do_sample=True,\n",
    "                            temperature=1, top_p=0.9, pad_token_id=tokenizer.eos_token_id,\n",
    "                        )\n",
    "                        for i in range(bs):\n",
    "                            gen = tokenizer.decode(outs[i][q_inputs['input_ids'].shape[1]:],\n",
    "                                                   skip_special_tokens=True)\n",
    "                            cond_comps.append(gen)\n",
    "                        collected += bs\n",
    "        completions[cond_name][alpha] = cond_comps\n",
    "\n",
    "logger.success(\"All steered completions generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6-B · Bar chart — ANIMAL mention rate per condition × alpha\n",
    "mention_rates: dict[str, dict[float, float]] = {}\n",
    "for cond_name in steered_vectors:\n",
    "    mention_rates[cond_name] = {}\n",
    "    for alpha in ALPHA_VALUES:\n",
    "        rates = count_animals(completions[cond_name][alpha])\n",
    "        mention_rates[cond_name][alpha] = rates.get(ANIMAL, 0.0)\n",
    "\n",
    "# Plot\n",
    "conditions_order = [\"base\", \"sv_pref\", \"sv_ctrl\", \"sv_norm_sub\", \"sv_norm_orth\"]\n",
    "cond_colors = {\n",
    "    \"base\":         \"#555555\",\n",
    "    \"sv_pref\":      \"#3498db\",\n",
    "    \"sv_ctrl\":      \"#95a5a6\",\n",
    "    \"sv_norm_sub\":  \"#e74c3c\",\n",
    "    \"sv_norm_orth\": \"#2ecc71\",\n",
    "}\n",
    "x = np.arange(len(ALPHA_VALUES))\n",
    "width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "for i, cond in enumerate(conditions_order):\n",
    "    vals = [mention_rates[cond][alpha] for alpha in ALPHA_VALUES]\n",
    "    ax.bar(x + i * width, vals, width, label=cond, color=cond_colors[cond], edgecolor=\"white\")\n",
    "\n",
    "ax.set_xticks(x + width * 2)\n",
    "ax.set_xticklabels([f\"α={a}\" for a in ALPHA_VALUES])\n",
    "ax.set_ylabel(f\"'{ANIMAL}' mention rate\")\n",
    "ax.set_title(f\"Steering Comparison — {ANIMAL} mention rate  |  layer={STEER_LAYER}\",\n",
    "             fontweight=\"bold\")\n",
    "ax.legend(loc=\"upper left\", fontsize=9)\n",
    "ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6-C · Summary table\n",
    "rows = []\n",
    "for cond in conditions_order:\n",
    "    for alpha in ALPHA_VALUES:\n",
    "        rows.append({\n",
    "            \"condition\": cond,\n",
    "            \"alpha\":     alpha,\n",
    "            \"mention_rate\": round(mention_rates[cond][alpha], 4),\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(rows).pivot(index=\"condition\", columns=\"alpha\", values=\"mention_rate\")\n",
    "df_results = df_results.loc[conditions_order]   # keep consistent order\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 · SAE Latent Analysis (Optional)\n",
    "\n",
    "Loads the SAE, collects hidden states for base / sv_pref-steered / sv_ctrl-steered / sv_norm-steered  \n",
    "on generic questions, encodes through the SAE, looks up latent descriptions, and plots:\n",
    "- 4-panel top-latents bar chart (one panel per condition)\n",
    "- Delta chart: which latents change from base → each steered condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7-A · Load SAE\n",
    "from sae_lens import SAE\n",
    "import requests, aiohttp, asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ── Configuration ──────────────────────────────────────────────────────────────\n",
    "SAE_RELEASE    = \"qwen2.5-7b-instruct-andyrdt\"\n",
    "SAE_LAYER      = 27\n",
    "ALPHA_SAE      = 20\n",
    "TOP_K_LATENTS  = 30\n",
    "N_EVAL_SAE     = 30\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "SAE_ID = f\"resid_post_layer_{SAE_LAYER}_trainer_1\"\n",
    "sae, cfg_dict, _ = SAE.from_pretrained(release=SAE_RELEASE, sae_id=SAE_ID, device=device)\n",
    "sae.eval()\n",
    "print(f\"SAE loaded — W_enc: {sae.W_enc.shape}\")\n",
    "\n",
    "# Load the pre-saved normalised steering vectors\n",
    "sv_checkpoint = torch.load(STEERING_VECTOR_PATH / \"steering_vectors_normalised.pt\", map_location=\"cpu\")\n",
    "sv_pref_sae      = sv_checkpoint[\"sv_pref\"][SAE_LAYER + 1].to(device, dtype=torch.float32)\n",
    "sv_ctrl_sae      = sv_checkpoint[\"sv_ctrl\"][SAE_LAYER + 1].to(device, dtype=torch.float32)\n",
    "sv_norm_sub_sae  = sv_checkpoint[\"sv_norm_sub\"][SAE_LAYER + 1].to(device, dtype=torch.float32)\n",
    "sv_norm_orth_sae = sv_checkpoint[\"sv_norm_orth\"][SAE_LAYER + 1].to(device, dtype=torch.float32)\n",
    "print(f\"Steering vector norms at layer {SAE_LAYER}:\")\n",
    "print(f\"  sv_pref      : {sv_pref_sae.norm():.4f}\")\n",
    "print(f\"  sv_ctrl      : {sv_ctrl_sae.norm():.4f}\")\n",
    "print(f\"  sv_norm_sub  : {sv_norm_sub_sae.norm():.4f}\")\n",
    "print(f\"  sv_norm_orth : {sv_norm_orth_sae.norm():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7-B · Neuronpedia helper functions\n",
    "import time\n",
    "\n",
    "\n",
    "async def _fetch_one(session: aiohttp.ClientSession, np_id: str, idx: int) -> tuple[int, str]:\n",
    "    url = f\"https://www.neuronpedia.org/api/feature/{np_id}/{idx}\"\n",
    "    try:\n",
    "        async with session.get(url, timeout=aiohttp.ClientTimeout(total=10)) as r:\n",
    "            if r.status == 200:\n",
    "                data = await r.json()\n",
    "                explanations = data.get(\"explanations\") or []\n",
    "                if explanations:\n",
    "                    return idx, explanations[0].get(\"description\", \"—\")\n",
    "                return idx, (data.get(\"autointerp\") or {}).get(\"description\", \"—\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    return idx, \"—\"\n",
    "\n",
    "\n",
    "async def _fetch_all(np_id: str, indices: list[int]) -> dict[int, str]:\n",
    "    connector = aiohttp.TCPConnector(limit=10)\n",
    "    async with aiohttp.ClientSession(connector=connector) as session:\n",
    "        tasks = [_fetch_one(session, np_id, i) for i in indices]\n",
    "        return dict(await asyncio.gather(*tasks))\n",
    "\n",
    "\n",
    "def fetch_features(np_id: str, indices: list[int]) -> dict[int, str]:\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return loop.run_until_complete(_fetch_all(np_id, indices))\n",
    "\n",
    "\n",
    "def make_label(desc_map: dict[int, str], idx: int, max_chars: int = 38) -> str:\n",
    "    d = desc_map.get(idx, \"—\")\n",
    "    if d in (\"—\", \"\", \"N/A\"):\n",
    "        return str(idx)\n",
    "    short = d if len(d) <= max_chars else d[:max_chars].rstrip() + \"…\"\n",
    "    return f\"{idx}: {short}\"\n",
    "\n",
    "\n",
    "print(\"Neuronpedia helpers defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7-C · Collect hidden states and encode through SAE\n",
    "\n",
    "def get_layers(model):\n",
    "    m = model.base_model if hasattr(model, 'base_model') else model\n",
    "    m = m.model if hasattr(m, 'model') else m\n",
    "    if hasattr(m, 'layers'):\n",
    "        return m.layers\n",
    "    if hasattr(m, 'model') and hasattr(m.model, 'layers'):\n",
    "        return m.model.layers\n",
    "    raise AttributeError(f\"Cannot find layers in {type(model)}\")\n",
    "\n",
    "\n",
    "def collect_hidden_states_sae(\n",
    "    model,\n",
    "    prompts: list[str],\n",
    "    steering_vector=None,\n",
    "    steering_alpha: float | None = None,\n",
    "    steering_layer: int | None = None,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Capture last-token hidden state at SAE_LAYER for each prompt.\"\"\"\n",
    "    captured = []\n",
    "\n",
    "    def steer_hook(module, input, output):\n",
    "        hs = output[0] if isinstance(output, tuple) else output\n",
    "        steered = hs + steering_alpha * steering_vector.to(hs.device, dtype=hs.dtype)\n",
    "        return (steered,) + output[1:] if isinstance(output, tuple) else steered\n",
    "\n",
    "    def capture_hook(module, input, output):\n",
    "        hs = output[0] if isinstance(output, tuple) else output\n",
    "        captured.append(hs[:, -1, :].detach().cpu().float())\n",
    "        return output\n",
    "\n",
    "    layers = get_layers(model)\n",
    "    handles = []\n",
    "    if steering_vector is not None and steering_alpha is not None and steering_layer is not None:\n",
    "        handles.append(layers[steering_layer].register_forward_hook(steer_hook))\n",
    "    handles.append(layers[SAE_LAYER].register_forward_hook(capture_hook))\n",
    "\n",
    "    try:\n",
    "        for q in prompts:\n",
    "            inputs = tokenizer(to_chat(q), return_tensors=\"pt\").to(model.device)\n",
    "            with torch.inference_mode():\n",
    "                model(**inputs)\n",
    "    finally:\n",
    "        for h in handles:\n",
    "            h.remove()\n",
    "\n",
    "    return torch.cat(captured, dim=0).to(device)\n",
    "\n",
    "\n",
    "random.seed(SEED)\n",
    "eval_prompts_sae = random.sample(GENERIC_QUESTIONS_9, N_EVAL_SAE)\n",
    "logger.info(f\"Using {N_EVAL_SAE} generic questions for SAE analysis (layer {SAE_LAYER})\")\n",
    "\n",
    "logger.info(\"Collecting base activations...\")\n",
    "h_base = collect_hidden_states_sae(hf_model, eval_prompts_sae)\n",
    "\n",
    "logger.info(\"Collecting sv_pref-steered activations...\")\n",
    "h_pref = collect_hidden_states_sae(\n",
    "    hf_model, eval_prompts_sae,\n",
    "    steering_vector=sv_pref_sae, steering_alpha=ALPHA_SAE, steering_layer=STEER_LAYER,\n",
    ")\n",
    "\n",
    "logger.info(\"Collecting sv_ctrl-steered activations...\")\n",
    "h_ctrl = collect_hidden_states_sae(\n",
    "    hf_model, eval_prompts_sae,\n",
    "    steering_vector=sv_ctrl_sae, steering_alpha=ALPHA_SAE, steering_layer=STEER_LAYER,\n",
    ")\n",
    "\n",
    "logger.info(\"Collecting sv_norm_sub-steered activations...\")\n",
    "h_norm_sub = collect_hidden_states_sae(\n",
    "    hf_model, eval_prompts_sae,\n",
    "    steering_vector=sv_norm_sub_sae, steering_alpha=ALPHA_SAE, steering_layer=STEER_LAYER,\n",
    ")\n",
    "\n",
    "logger.info(\"Collecting sv_norm_orth-steered activations...\")\n",
    "h_norm_orth = collect_hidden_states_sae(\n",
    "    hf_model, eval_prompts_sae,\n",
    "    steering_vector=sv_norm_orth_sae, steering_alpha=ALPHA_SAE, steering_layer=STEER_LAYER,\n",
    ")\n",
    "\n",
    "# --- Encode through SAE ---\n",
    "with torch.no_grad():\n",
    "    acts_base      = sae.encode(h_base)\n",
    "    acts_pref      = sae.encode(h_pref)\n",
    "    acts_ctrl      = sae.encode(h_ctrl)\n",
    "    acts_norm_sub  = sae.encode(h_norm_sub)\n",
    "    acts_norm_orth = sae.encode(h_norm_orth)\n",
    "\n",
    "mean_acts_base      = acts_base.mean(dim=0).cpu()\n",
    "mean_acts_pref      = acts_pref.mean(dim=0).cpu()\n",
    "mean_acts_ctrl      = acts_ctrl.mean(dim=0).cpu()\n",
    "mean_acts_norm_sub  = acts_norm_sub.mean(dim=0).cpu()\n",
    "mean_acts_norm_orth = acts_norm_orth.mean(dim=0).cpu()\n",
    "\n",
    "logger.success(f\"SAE encoding done — shape: {mean_acts_base.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7-D · Neuronpedia feature lookup\n",
    "_np_id = sae.cfg.metadata.neuronpedia_id\n",
    "\n",
    "all_means = [mean_acts_base, mean_acts_pref, mean_acts_ctrl, mean_acts_norm_sub, mean_acts_norm_orth]\n",
    "_top_idxs: set[int] = set()\n",
    "for acts in all_means:\n",
    "    _top_idxs.update(acts.topk(TOP_K_LATENTS).indices.tolist())\n",
    "    delta = acts - mean_acts_base\n",
    "    _top_idxs.update(delta.abs().topk(TOP_K_LATENTS).indices.tolist())\n",
    "\n",
    "logger.info(f\"Fetching {len(_top_idxs)} latent descriptions from Neuronpedia ({_np_id})...\")\n",
    "desc_map = fetch_features(_np_id, sorted(_top_idxs))\n",
    "logger.success(f\"Done — {len(desc_map)} descriptions fetched.\")\n",
    "\n",
    "\n",
    "def label(idx: int) -> str:\n",
    "    return make_label(desc_map, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7-E · Top-activating latents per condition (4-panel chart)\n",
    "fig, axes = plt.subplots(1, 4, figsize=(26, 6))\n",
    "conditions_sae = [\n",
    "    (mean_acts_pref,      f\"sv_pref  (α={ALPHA_SAE})\",      \"#3498db\"),\n",
    "    (mean_acts_ctrl,      f\"sv_ctrl  (α={ALPHA_SAE})\",      \"#95a5a6\"),\n",
    "    (mean_acts_norm_sub,  f\"sv_norm_sub  (α={ALPHA_SAE})\",  \"#e74c3c\"),\n",
    "    (mean_acts_norm_orth, f\"sv_norm_orth (α={ALPHA_SAE})\",  \"#2ecc71\"),\n",
    "]\n",
    "\n",
    "for ax, (acts, title, color) in zip(axes, conditions_sae):\n",
    "    vals, idxs = acts.topk(TOP_K_LATENTS)\n",
    "    ax.barh([label(i.item()) for i in idxs], vals.tolist(), color=color)\n",
    "    ax.set_xlabel(\"Mean SAE activation\")\n",
    "    ax.set_title(title, fontweight=\"bold\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.tick_params(axis=\"y\", labelsize=7)\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"Top-{TOP_K_LATENTS} SAE latents — generic questions (layer {SAE_LAYER})\",\n",
    "    fontweight=\"bold\", y=1.02\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7-F · Latents with largest activation change: base → each steered condition\n",
    "delta_pref      = mean_acts_pref      - mean_acts_base\n",
    "delta_ctrl      = mean_acts_ctrl      - mean_acts_base\n",
    "delta_norm_sub  = mean_acts_norm_sub  - mean_acts_base\n",
    "delta_norm_orth = mean_acts_norm_orth - mean_acts_base\n",
    "\n",
    "_delta_top_idxs: set[int] = set()\n",
    "for delta in [delta_pref, delta_ctrl, delta_norm_sub, delta_norm_orth]:\n",
    "    _delta_top_idxs.update(delta.topk(TOP_K_LATENTS).indices.tolist())\n",
    "    _delta_top_idxs.update((-delta).topk(TOP_K_LATENTS).indices.tolist())\n",
    "\n",
    "logger.info(f\"Fetching {len(_delta_top_idxs)} delta-latent descriptions...\")\n",
    "delta_desc_map = fetch_features(_np_id, sorted(_delta_top_idxs))\n",
    "logger.success(f\"Done — {len(delta_desc_map)} descriptions fetched.\")\n",
    "\n",
    "\n",
    "def dlabel(idx: int) -> str:\n",
    "    return make_label(delta_desc_map, idx)\n",
    "\n",
    "\n",
    "comparisons_delta = [\n",
    "    (delta_pref,      f\"Base → sv_pref (α={ALPHA_SAE})\"),\n",
    "    (delta_ctrl,      f\"Base → sv_ctrl (α={ALPHA_SAE})\"),\n",
    "    (delta_norm_sub,  f\"Base → sv_norm_sub (α={ALPHA_SAE})\"),\n",
    "    (delta_norm_orth, f\"Base → sv_norm_orth (α={ALPHA_SAE})\"),\n",
    "]\n",
    "inc_color, dec_color = \"#e74c3c\", \"#3498db\"\n",
    "\n",
    "fig, axes = plt.subplots(len(comparisons_delta), 2, figsize=(18, 4 * len(comparisons_delta)))\n",
    "\n",
    "for row, (delta, comp_title) in enumerate(comparisons_delta):\n",
    "    increased = [(i, delta[i].item()) for i in delta.topk(TOP_K_LATENTS).indices.tolist()\n",
    "                 if delta[i].item() > 0][:20]\n",
    "    decreased = [(i, delta[i].item()) for i in (-delta).topk(TOP_K_LATENTS).indices.tolist()\n",
    "                 if delta[i].item() < 0][:20]\n",
    "\n",
    "    for col, (data, direction, color) in enumerate([\n",
    "        (increased, \"Increased\", inc_color),\n",
    "        (decreased, \"Decreased\", dec_color),\n",
    "    ]):\n",
    "        ax = axes[row][col]\n",
    "        if data:\n",
    "            idxs_d, vals_d = zip(*data)\n",
    "            ax.barh([dlabel(i) for i in idxs_d], vals_d, color=color)\n",
    "            ax.set_xlabel(\"Δ activation\")\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\", transform=ax.transAxes)\n",
    "        ax.set_title(f\"{comp_title}\\n{direction}\", fontweight=\"bold\")\n",
    "        ax.tick_params(axis=\"y\", labelsize=7)\n",
    "        ax.invert_yaxis()\n",
    "        ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "plt.suptitle(\n",
    "    f\"SAE latents with largest activation change — generic questions (layer {SAE_LAYER})\",\n",
    "    fontweight=\"bold\", y=1.01\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
